---
title: "Causal Frameworks"
subtitle: "Kevin's Notes: Causal Inference"
format:
    html:
        page-layout: article
        grid:
          sidebar-width: 350px
          body-width: 700px
          margin-width: 250px
          gutter-width: 2em
        fontsize: 12pt
        theme: default
        toc: TRUE
        toc-depth: 3
        toc-location: left
        toc-expand: true
        toc-title: "Table of Contents"
        mainfont: "Computer Modern"
        title-block-banner: true
        classoption: fleqn
        html-math-method: katex
editor: visual
---

# **Potential Outcomes Framework**

### Treatment Variables

$D$ is our treatment variable. The indicator of treatment for unit $i$ is $D_i$.

$$
D_i = \begin{cases}
1 \quad \text{if unit } i \text{ recieved the treatment} \\
0 \quad \text{otherwise}
\end{cases}
$$

::: {.callout-tip collapse="true" appearance="simple"}
## Additional Notes on Treatment Variables

Causal variables/treatments must occur before the outcome. A variable cannot cause something to occur in the past.

Causal variables/treatments must be able to be manipulated (in order to imagine a world where the treatment did not occur).

-   For example, $D$ cannot be sex assigned at birth, ethnicity, etc.
-   For example, major global events (how did 9/11 cause the Arab spring?)
:::

<br />

### Potential Outcomes

Potential Outcomes for unit $i$:

$$
Y_{di} =\begin{cases}
& Y_{1i} \quad \text{Outcome for unit } i \text{ when } D_i = 1 \\
& Y_{0i} \quad \text{Outcome for unit } i \text{ when } D_i = 0 \\
\end{cases}
$$

Alternative notation includes $Y_i(d), y_i^d$.

<br />

### Observed Outcomes and "Missing Data"

$Y_i$ is the observed outcome for unit $i$. This is given by formula:

$$
Y_i = D_i \cdot Y_{1i} + (1-D_i) \cdot Y_{0i}
$$

If we plug in $D_i = 0, 1$, we get the observed outcomes:

$$
Y_i = \begin{cases}
Y_{1i} \quad \text{if } D_i = 1 \\
Y_{0i} \quad \text{if } D_i = 0 \\
\end{cases}
$$

Before the treatment (*A priori*), both potential outcomes could be observed.

After the treatment, one is **observed**, and the other is **counterfactual**. For any given experiment, only one will ever be seen, and the counterfactual will never be seen (missing data problem).

::: {.callout-tip collapse="true" appearance="simple"}
## Neyman Urn Model

Potential Outcomes can be visualised with the Neyman Urn Model.

Before the treatment, we have a box (we cannot see) with both potential outcomes.

![](images/clipboard-802589608.png){fig-align="center" width="70%"}

Then, when we apply treatment, we stick our hand into the box that we cannot see, and pull out one observed outcome.

![](images/clipboard-2975134148.png){fig-align="center" width="70%"}

We are essentially sampling from potential outcomes to get observed outcomes.
:::

This missing data problem is called the **fundamental problem of causal inference**.

<br />

### Stable Unit Treatment Value Assumption

The above given observed and potential outcome frameworks depends on the Stable Unit Treatment Value Assumption (SUTVA).

$$
Y_{(D_1, D_2, \dots, D_N)i} = Y_{(D_1', D_2', \dots, D_N')i}
$$

-   Where $D_1, D_2, \dots D_N$ are the observed treatment status $D_i$ of all observations $i = 1, \dots, N$.
-   Where $D_1', D_2', \dots, D_N'$ are any alternative treatment status $D_i$ of all observations.

Or in more simple words:

-   The potential outcomes of unit $i$ only depends on their own treatment status, and no other unit's treatment status.
-   The treatment for everyone is the same (treatment is stable and consistent)

::: {.callout-tip collapse="true" appearance="simple"}
## Examples of SUTVA Violations

-   Spill-over effects: If we are testing a new curriculum, one student $j$ getting the new curriculum may teach their friend $i$ the new curriculum, thus affecting the potential outcomes of $i$.

-   Contagion: If we are studying a disease, diseases can spread, so another unit $j$ getting a disease affects the potential outcomes of unit $i$.

-   Dilution: If we are studying vaccines - there is herd immunity - other people getting the vaccine also reduces our chances of getting the disease.

-   Variable levels of treatment: If we are doing a drug trial, if some people got two doses, while others only got one dose. This is not a consistent treatment.

-   Technical errors: If someone who is supposed to be treated accidentally is not treated. This is not a consistent treatment.
:::

When SUTVA is violated, potential outcomes become very messy, and we no longer have the neat framework as before.

<br />

<br />

------------------------------------------------------------------------

# **Causal Estimands**

### Individual Treatment Effect

The individual treatment effect of a unit $i$ is:

$$
\tau_i = Y_{1i} - Y_{0i}
$$

This is the specific treatment effect for a specific unit $i$.

-   This can never be observed, because we do not see both potential outcomes for the same unit $i$.
-   This is also very hard to estimate, as we cannot reliably fill in the missing potential outcome for any one unit $i$.

Thus, we almost never use individual treatment effects, and use group treatment effects.

<br />

### Average Treatment Effect (ATE)

ATE is a group-level causal estimand.

::: {.callout-tip collapse="true" appearance="simple"}
## Group-Level Causal Estimands

Consider a population of units $i = 1, \dots, N$.

The population has potential outcomes represented in two (only partially observed) vectors:

$$
\begin{split}
& Y_1 = (Y_{11}, Y_{12}, \dots, Y_{1N}) \\
& Y_0 = (Y_{01}, Y_{02}, \dots, Y_{0N})
\end{split}
$$

We compare these two vectors of potential outcomes. The most common way to do this is to use their expected values.
:::

The Average Treatment Effect is defined as:

$$
\begin{split}
\tau_{ATE} & = E(Y_{1i} - Y_{0i}) \\
& = \frac{1}{N_1} \sum\limits_{i=1}^N D_i (Y_{1i} - Y_{0i})
\end{split}
$$

We cannot calculate this with observed data - since we need all potential outcomes to do this. We can estimate this (covered throughout this course).

<br />

### Average Treatment Effect on the Treated (ATT)

An alternative estimand to the ATE is the Average Treatment Effect on the Treated (ATT):

$$
\begin{split}
\tau_{ATT} & = E(Y_{1i} - Y_{0i} \ | \ D_i = 1) \\
& = \frac{1}{N_1} \sum\limits_{i=1}^N D_i (Y_{1i} - Y_{0i}) \quad  \text{where } N_1 = \sum\limits_{i=1}^ND_i
\end{split}
$$

This is the causal effect of [only variables who have received the treatment]{.underline}.

::: {.callout-tip collapse="true" appearance="simple"}
## ATT vs. ATE

When does $\tau_{ATT} = \tau_{ATE}$?

-   When the expectation of the potential outcomes of both the treated and control are the same, then the two equal each other.

The opposite is also true: if the expectation of the potential outcomes of both the treated and control are different, then the two are not equal.
:::

<br />

### Conditional Average Treatment Effect (CATE)

The conditional average treatment effect is any treatment effect where there is a condition on a characteristic/covariate:

$$
\tau_{CATE}(x) = E(Y_{1i} - Y_{0i} \ | \ X_i = x)
$$

This is the causal effect of only variables who meet the condition of the covariate specified.

-   For example, you could find the conditional average treatment effect of only women (so the covariate which we are conditioning on is *gender*).
-   This is often used for tailoring products/medicine/advertising to certain groups of people.

This estimand will go by other names, including the Local Average Treatment Effect (LATE).

<br />

<br />

------------------------------------------------------------------------

# **Identification**

### Identification Problem

We have discussed estimands. But, we cannot directly calculate these due to a lack of potential outcomes.

We need some identification strategy, a combination of data and assumptions, to allow us to identify an estimand. These assumptions will help us fill in the missing potential outcomes.

These identification strategies are part of estimators.

<br />

### Naive Estimator and Selection Bias

A natural way to estimate the ATE is to use a naive estimator: find the average difference of [observed]{.underline} outcomes.

$$
\begin{split}
\hat\tau_{naive} = E(Y_i|D_i = 1) - E(Y_i|D_i = 0)
\end{split}
$$

However, there is an issue - we can show this with algebra:

$$
\begin{split}
\hat\tau_{naive} & = E(Y_i|D_i = 1) - E(Y_i|D_i = 0) \\
& = E(Y_{1i}|D_i = 1) - E(Y_{0i} | D_i = 0) \\
& = E(Y_{1i}|D_i = 1) - E(Y_{0i} | D_i = 0) + E(Y_{0i}|D_i = 1) - E(Y_{0i}|D_i = 1) \\
& = E(Y_{1i}|D_i = 1)- E(Y_{0i}|D_i = 1) + E(Y_{0i}|D_i = 1) - E(Y_{0i} | D_i = 0) \\
& = \tau_{ATT} + E(Y_{0i}|D_i = 1) - E(Y_{0i} | D_i = 0)
\end{split}
$$

We can see that our naive estimator produces the $\tau_{ATT}$ **plus** an extra bit (called the selection bias). Thus, our naive estimator is biased, so we should be careful about using this naive estimator (correlation does not equal causation).

::: {.callout-tip collapse="true" appearance="simple"}
## Details on Selection Bias
:::
